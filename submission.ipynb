{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9mdOXEPG-1o"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vw-CHSECHEqq",
    "outputId": "5542fb24-b274-4685-925b-98d04196a512"
   },
   "outputs": [],
   "source": [
    "# Define the transformations for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to Tensor\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),  # Normalize with CIFAR-100 mean and std\n",
    "])\n",
    "\n",
    "# Download the CIFAR-100 training dataset\n",
    "train_dataset = datasets.CIFAR100(\n",
    "    root='./data',       # Change this path if needed\n",
    "    train=True,          # Set to True to download the training set\n",
    "    download=True,       # Set to True to download if not already downloaded\n",
    "    transform=transform  # Apply transformations\n",
    ")\n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Create a DataLoader for batch processing\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,      # Batch size (you can modify this as needed)\n",
    "    shuffle=True        # Shuffle data for training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "bMSDUabBHLSk",
    "outputId": "f8585c9d-85f1-4518-9272-1375117ad4b5"
   },
   "outputs": [],
   "source": [
    "# Accessing one batch of images and labels\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Batch of images shape: {images.shape}\")  # Should output torch.Size([64, 3, 32, 32])\n",
    "print(f\"Batch of labels: {labels}\")\n",
    "\n",
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    img = img * torch.tensor((0.2675, 0.2565, 0.2761)).view(3,1,1) + torch.tensor((0.5071, 0.4867, 0.4408)).view(3,1,1)  # Unnormalize\n",
    "    img = img.numpy()\n",
    "    img = np.transpose(img, (1, 2, 0))  # Convert from Tensor image\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# Show images\n",
    "import torchvision\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# Print labels\n",
    "print(' '.join(f'{labels[j].item()}' for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHyoe_Y2HNxT",
    "outputId": "fdcbdac9-ceb3-4f45-a833-33c1c76ef153"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 100)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "dataset_sizes = len(train_dataset)\n",
    "indices = list(range(dataset_sizes))\n",
    "split = int(np.floor(0.2 * dataset_sizes))\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwP0AFhxHRoL"
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    model.train()\n",
    "    overall_loss = 0\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        overall_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = overall_loss / len(train_loader.dataset)\n",
    "    print(f'Training Loss: {epoch_loss}')\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images, labels = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    print(f'Validation Loss: {val_loss}, Accuracy: {accuracy}')\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "ukH81UNZHSOp",
    "outputId": "3127275d-f25a-4658-a927-3253e97da05b"
   },
   "outputs": [],
   "source": [
    "print(\"Generating predictions on test set\")\n",
    "\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzWX04tYHXYN"
   },
   "outputs": [],
   "source": [
    "class CIFAR100TestDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.pixel_columns = [f'pixel_{i}' for i in range(1, 3073)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pixel_data = self.dataframe.iloc[idx][self.pixel_columns].values.astype(np.uint8)\n",
    "        image = pixel_data.reshape(3, 32, 32)\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        img = Image.fromarray(image)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        ID = int(self.dataframe.iloc[idx]['ID'])\n",
    "        return img, ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsK1F170HclN"
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
    "                         (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "test_dataset = CIFAR100TestDataset(test_df, transform=test_transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxNG239LHgk0"
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 100)\n",
    "model.load_state_dict(torch.load('cifar100_resnet18.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_IDs = []\n",
    "all_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoaWHMjhHipb"
   },
   "outputs": [],
   "source": [
    "all_IDs = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, IDs in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        preds = preds.cpu().numpy()\n",
    "        IDs = IDs.numpy()\n",
    "        all_IDs.extend(IDs)\n",
    "        all_predictions.extend(preds)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': all_IDs,\n",
    "    'LABEL': all_predictions\n",
    "})\n",
    "\n",
    "submission_df = submission_df.sort_values(by='ID').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPCPYr35HkAu"
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print('Submission file saved as submission.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
